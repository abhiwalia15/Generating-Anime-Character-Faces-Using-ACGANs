{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final_NNDL_01.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Give a name to the Project and Import the dataset from the URL."
      ],
      "metadata": {
        "id": "lYcOrBNnT8o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ProjectName = \"Generating Anime Character Faces Using ACGANs\"\n",
        "\n",
        "!pip install opendatasets --upgrade --quiet"
      ],
      "metadata": {
        "id": "wRX9GU8dfdkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRhT7S_YOfd1"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "\n",
        "dataset = 'https://www.kaggle.com/splcher/animefacedataset'\n",
        "od.download(dataset)\n",
        "\n",
        "import os\n",
        "\n",
        "Data_Dir = './animefacedataset'\n",
        "print(os.listdir(Data_Dir + '/images')[:25])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-process (Normalize) the Training dataset"
      ],
      "metadata": {
        "id": "SEvwz9RbUzpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# resize training data to be of size 64x64\n",
        "ImageSize = 64\n",
        "\n",
        "# send images in the batch size of 128\n",
        "BatchSize = 128\n",
        "\n",
        "# Set the parameters to normalize the image in range of -1,1\n",
        "stat = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "\n",
        "# Normalize the entire dataset to avoid weight normalities or abnorla behaviour of the dataset\n",
        "trainDS = ImageFolder(Data_Dir, transform=T.Compose([T.Resize(ImageSize), T.CenterCrop(ImageSize), T.ToTensor(), T.Normalize(*stat)]))\n",
        "\n",
        "# Normalize the data containing faces \n",
        "trainDL = DataLoader(trainDS, BatchSize, shuffle=True, num_workers=3, pin_memory=True)\n",
        "\n",
        "# helper method to denormalize the tensors of images and display some smaples from the data\n",
        "def denorm(ImgTensors):\n",
        "    return ImgTensors * stat[1][0] + stat[0][0]\n",
        "\n",
        "# helper method to display the samples images after denormalizing them\n",
        "def ShowImages(image, nmax=64):\n",
        "    figure, axis = plt.subplots(figsize=(9, 9))\n",
        "    axis.set_xticks([]); axis.set_yticks([])\n",
        "    axis.imshow(make_grid(denorm(image.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "# Helper method to plot denormalized images in from the given batches of data\n",
        "def ShowBatch(DL, nmax=32):\n",
        "    for image, _ in DL:\n",
        "        ShowImages(image, nmax)\n",
        "        break\n",
        "\n",
        "# call the function\n",
        "ShowBatch(trainDL)"
      ],
      "metadata": {
        "id": "x1cYbhfHc3vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Function to Use the GPU/ CUDA on N-VIDIA "
      ],
      "metadata": {
        "id": "cmh9sOpDYFAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function to pick GPU is available, else select CPU\n",
        "def Get_Default_Device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "# utility function to move tensors to the chosen device from previous state\n",
        "def To_Device(Data, Device):\n",
        "    if isinstance(Data, (list,tuple)):\n",
        "        return [To_Device(x, Device) for x in Data]\n",
        "    return Data.to(Device, non_blocking=True)\n",
        "\n",
        "# Driver Class to wrap a dataloader to move to the selected device\n",
        "class Device_Data_Loader():\n",
        "    def __init__(self, Dl, Device):\n",
        "        self.Dl = Dl\n",
        "        self.Device = Device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for i in self.Dl: \n",
        "            yield To_Device(i, self.Device)\n",
        "    \n",
        "    # return the number of batches\n",
        "    def __len__(self):\n",
        "        return len(self.Dl)\n",
        "\n",
        "Device = Get_Default_Device()\n",
        "Device\n",
        "\n",
        "\n",
        "trainDL = Device_Data_Loader(trainDL, Device)"
      ],
      "metadata": {
        "id": "cMHSrZnD_iLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator Network Architecture"
      ],
      "metadata": {
        "id": "1mOtlMghZlJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# design the discriminator architecture\n",
        "Disc = nn.Sequential(\n",
        "    \n",
        "    # first layer has input 3*64*64 and output of 64*32*32\n",
        "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "    # second layer has input same as the output of previous layer and its own output of 128*16*16\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "    # Third hidden layer has an output of 256*8*8\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "    # fourth hidden layer has an output of 512*4*4 \n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "    # last output layer has output of 1*1*1\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "\n",
        "    # At last, we use a sigmoid activation function as it is a binary classification problem and a flatten layer to reshape the output\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "Disc = To_Device(Disc, Device)"
      ],
      "metadata": {
        "id": "vKDMsoNefzFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Design the Discriminator network architecture"
      ],
      "metadata": {
        "id": "nHts40gRw1j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LatentSize = 128\n",
        "Gene = nn.Sequential(\n",
        "    \n",
        "    # Give the input of latent size and 1*1 and output a size of 512*4*4\n",
        "    nn.ConvTranspose2d(LatentSize, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    # input from previous layer and output a kernel of size 256*8*8\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    # input from previous layer and output of 128*16*16\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    # input from previous layer and output of size 64*32*32\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    # input from previou layer and final output of 3*64*64\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")\n",
        "\n",
        "# Generating random tensor vecotrs in the given size\n",
        "Ran_Tensor = torch.randn(BatchSize, LatentSize, 1, 1) \n",
        "\n",
        "# Now using the above network to generate fake samples\n",
        "FakeImages = Gene(Ran_Tensor)\n",
        "print(FakeImages.shape)\n",
        "\n",
        "# Show the generated fake image\n",
        "ShowImages(FakeImages)\n",
        "\n",
        "# choose GPu for generator network if available\n",
        "Gene = To_Device(Gene, Device)"
      ],
      "metadata": {
        "id": "qphDW-ucgFsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Discriminator and Generator Networks"
      ],
      "metadata": {
        "id": "nY0W3sb_282D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train discriminator\n",
        "def Train_Disc(Real_Images, Opt_D):\n",
        "    \n",
        "    # clear the discimininator gradients after evey epoch\n",
        "    Opt_D.zero_grad()\n",
        "\n",
        "    # In first iteration, we pass the real images and compute the loss setting the target labels to 1\n",
        "    Real_Preds = Disc(Real_Images)\n",
        "\n",
        "    Real_Targets = torch.ones(Real_Images.size(0), 1, device=Device)\n",
        "    \n",
        "    Real_Loss = F.binary_cross_entropy(Real_Preds, Real_Targets)\n",
        "    \n",
        "    Real_Score = torch.mean(Real_Preds).item()\n",
        "    \n",
        "    # Generate synthetic (fake) images using generator network\n",
        "    Latent = torch.randn(BatchSize, LatentSize, 1, 1, device=Device)\n",
        "    \n",
        "    Fake_Images = Gene(Latent)\n",
        "\n",
        "    # Compute the loss by passing images throught he disc. network\n",
        "    Fake_Targets = torch.zeros(Fake_Images.size(0), 1, device=Device)\n",
        "\n",
        "    Fake_Preds = Disc(Fake_Images)\n",
        "    \n",
        "    Fake_Loss = F.binary_cross_entropy(Fake_Preds, Fake_Targets)\n",
        "    \n",
        "    Fake_Score = torch.mean(Fake_Preds).item()\n",
        "\n",
        "    # Keep updating the weights of the disc. network\n",
        "    Loss = Real_Loss + Fake_Loss\n",
        "\n",
        "    Loss.backward()\n",
        "\n",
        "    Opt_D.step()\n",
        "    \n",
        "    return Loss.item(), Real_Score, Fake_Score\n",
        "\n",
        "\n",
        "# Function to train the generator network\n",
        "def Train_Gene(Opt_G):\n",
        "    \n",
        "    # clearning the generator gradients every epoch\n",
        "    Opt_G.zero_grad()\n",
        "    \n",
        "    # Generate synthetic (fake) images \n",
        "    Latent = torch.randn(BatchSize, LatentSize, 1, 1, device=Device)\n",
        "    \n",
        "    Fake_Images = Gene(Latent)\n",
        "    \n",
        "    # step to give the output to the deiscriminator to compute minimal loss\n",
        "    Preds = Disc(Fake_Images)\n",
        "\n",
        "    Targets = torch.ones(BatchSize, 1, device=Device)\n",
        "    \n",
        "    Loss = F.binary_cross_entropy(Preds, Targets)\n",
        "    \n",
        "    # Keep updating the weights of the generator network\n",
        "    Loss.backward()\n",
        "\n",
        "    Opt_G.step()\n",
        "    \n",
        "    return Loss.item()"
      ],
      "metadata": {
        "id": "yFYWksEdgVbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AQmI-u_MjoWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to save the output generated Images"
      ],
      "metadata": {
        "id": "_l9wAbB-4qPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the images generator by generator network\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "Sample_Dir = 'Generated Images'\n",
        "\n",
        "os.makedirs(Sample_Dir, exist_ok=True)\n",
        "\n",
        "# utility function\n",
        "def Save_Samples(Index, Latent_Tensors, show=True):\n",
        "    \n",
        "    Fake_Images = Gene(Latent_Tensors)\n",
        "    \n",
        "    Fake_Fname = 'Generated_Images-{0:0=4d}.png'.format(Index)\n",
        "    \n",
        "    save_image(denorm(FakeImages), os.path.join(Sample_Dir, Fake_Fname), nrow=8)\n",
        "    \n",
        "    print('Saving the images....', Fake_Fname)\n",
        "    \n",
        "    if show:\n",
        "\n",
        "        figure, axis = plt.subplots(figsize=(10, 10))\n",
        "      \n",
        "        axis.set_xticks([]); axis.set_yticks([])\n",
        "      \n",
        "        axis.imshow(make_grid(Fake_Images.cpu().detach(), nrow=4).permute(1, 2, 0))\n",
        "\n",
        "# save the first image from generator training(its output)\n",
        "Fixed_Latent = torch.randn(16, LatentSize, 1, 1, device=Device)\n",
        "\n",
        "Save_Samples(0, Fixed_Latent)"
      ],
      "metadata": {
        "id": "lXyUlyN7krGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets traing the disc. and generator in parallel for each batch of training data by calling fit method\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def Fit(Epochs, LR, Start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # array to store final scores\n",
        "    Losses_g = []\n",
        "    Losses_d = []\n",
        "    Real_scores = []\n",
        "    Fake_scores = []\n",
        "    \n",
        "    # Optimizers for disc. and generator networks\n",
        "    Opt_d = torch.optim.Adam(Disc.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "    Opt_g = torch.optim.Adam(Gene.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "    \n",
        "    for Epoch in range(Epochs):\n",
        "        for Real_images, _ in tqdm(trainDL):\n",
        "            \n",
        "            # start Training discriminator netowkr\n",
        "            Loss_d, Real_score, Fake_score = Train_Disc(Real_images, Opt_d)\n",
        "            # start Training generator netowkr\n",
        "            Loss_g = Train_Gene(Opt_g)\n",
        "            \n",
        "        # Store the loss and real scores for generator and disc. network\n",
        "        Losses_g.append(Loss_g)\n",
        "        Losses_d.append(Loss_d)\n",
        "        Real_scores.append(Real_score)\n",
        "        Fake_scores.append(Fake_score)\n",
        "        \n",
        "        # logging and scoring for last batches\n",
        "        print(\"Epoch ------> [{}/{}], Loss_gene: {:.4f}, Loss_disc: {:.4f}, Real_score: {:.4f}, Fake_score: {:.4f}\".format(\n",
        "            Epoch+1, Epochs, Loss_g, Loss_d, Real_score, Fake_score))\n",
        "    \n",
        "        # Save the output images \n",
        "        Save_Samples(Epoch + Start_idx, Fixed_Latent, show=False)\n",
        "    \n",
        "    # return their values\n",
        "    return Losses_g, Losses_d, Real_scores, Fake_scores\n",
        "\n",
        "# set the learning rate to 0.0002 and train for 1 epoch\n",
        "LR = 0.0002\n",
        "Epochs = 25\n",
        "\n",
        "# start training\n",
        "History = Fit(Epochs, LR)"
      ],
      "metadata": {
        "id": "2YNFn-dQlrFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate The Model"
      ],
      "metadata": {
        "id": "VGwT62EQqUTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the values to the set\n",
        "Losses_G, Losses_D, Real_Scores, Fake_Scores = History\n",
        "\n",
        "# show the predictions of the AC-GAN model\n",
        "from IPython.display import Image\n",
        "\n",
        "Image('./Generated Images/Generated_Images-0001.png')\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "o_lWFKsamVu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Real_Scores, '--')\n",
        "plt.plot(Fake_Scores, '--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Scores Plot');"
      ],
      "metadata": {
        "id": "rfaENpbarMZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the loss for generator and disc. networks \n",
        "plt.plot(Losses_D, '--')\n",
        "plt.plot(Losses_G, '--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Discriminator Network', 'Generator Network'])\n",
        "plt.title('Losses Plot');\n"
      ],
      "metadata": {
        "id": "HKMdu0r1rUkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('./Generated Images/Generated_Images-0001.png')\n",
        "Image('./Generated Images/Generated_Images-0005.png')\n",
        "Image('./Generated Images/Generated_Images-00010.png')\n",
        "Image('./Generated Images/Generated_Images-00020.png')\n",
        "Image('./Generated Images/Generated_Images-00025.png')\n",
        "\n",
        "# Save the model checkpoints and weights for future references\n",
        "torch.save(Gene.state_dict(), 'Generator.pth')\n",
        "torch.save(Disc.state_dict(), 'Discriminator.pth')"
      ],
      "metadata": {
        "id": "oF6Zr_qgrVAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank you!"
      ],
      "metadata": {
        "id": "OaEn6GIzb3mA"
      }
    }
  ]
}